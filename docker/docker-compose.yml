# docker-compose.yml
version: '3.8'
services:
#  backend:
#    build:
#      context: ../../cruming-server
#      dockerfile: Dockerfile
#    image: backend_app:latest
#    container_name: backend_server
##    volumes:
##      - ./config/backend-config:/app/config
#    ports:
#      - "8080:8080"  #HTTP
#    environment:
#      - AI_SERVICE_URL=http://localhost:5000 # 추후 ai URL이 정해지면 변경
#    logging:
#      driver : "fluentd"
#      options:
#        fluentd-address: fluentd:24224
#        tag: backend_service
#    healthcheck:
#      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
#      interval: 30s
#      timeout: 10s
#      retries: 3
#
#
#  ai:
#    build:
#      context: ../../cruming-ai
#      dockerfile: Dockerfile
#    image: ai_app:latest
#    container_name: ai_server
#    volumes:
#      - ../../cruming-ai/model:/app/model
#    ports:
#      - "5000:5000"  #API
#    logging:
#      driver: "fluentd"
#      options:
#        fluentd-address: fluentd:24224
#        tag: ai_service




  elasticsearch:
    image: elasticsearch:7.17.10
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      - ./backup:/usr/share/elasticsearch/backup
    deploy:
      resources:
        limits:
          memory: 1g
        reservations:
          memory: 512m

  kibana:
    image: kibana:7.17.10
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
       - "5601:5601"
    deploy:
      resources:
        limits:
          memory: 512m
        reservations:
          memory: 256m
#    labels:
#      - "traefik.enable=true"
#      - "traefik.http.routers.kibana.rule=Host(`kibana.localhost`)"
#      - "traefik.http.routers.kibana.entrypoints=websecure"
#      - "traefik.http.routers.kibana.tls.certresolver=myresolver"

  #    depends_on:
#      - elasticsearch

  fluentd:
    build:
      context: ./fluentd
      dockerfile: Dockerfile
    image: fluent_custom:latest #이미지 이름의 태그
    container_name: fluentd
    volumes:
      - ./fluentd/fluent.conf:/fluentd/etc/fluent.conf
    ports:
      - "24224:24224"
      - "24224:24224/udp"
      - "24231:24231" # Prometheus Exporter 포트
    environment:
      - FLUENTD_WORKERS=2
    deploy:
      resources:
        limits:
          memory: 256m
        reservations:
          memory: 128m

  #    depends_on:
#      - elasticsearch


  prometheus:
    image: prom/prometheus:v2.43.1
    container_name: prometheus
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.retention.time=30d'  # 데이터 보존 기간을 30일로 설정
      - '--web.external-url=http://localhost:9090'
      - '--web.route-prefix=/'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.no-lockfile'
#      - '--enable-feature=prometheus_remote_write'
#      - '--remote-write.url=http://thanos:10901/api/v1/receive'
    ports:
       - "9090:9090"

  grafana:
    image: grafana/grafana-oss:9.5.3
    container_name: grafana
    ports:
      - "3000:3000"
#    depends_on:
#      - prometheus
#    labels:
#      - "traefik.enable=true"
#      - "traefik.http.routers.grafana.rule=Host(`grafana.localhost`)"
#      - "traefik.http.routers.grafana.entrypoints=websecure"
#      - "traefik.http.routers.grafana.tls.certresolver=myresolver"


  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    restart: unless-stopped
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'

  init-elasticsearch:
    image: curlimages/curl:latest
    container_name: init-elasticsearch
    depends_on:
      - elasticsearch
    volumes:
      - ./init-elasticsearch.sh:/init-elasticsearch.sh
    entrypoint: [ "sh", "/init-elasticsearch.sh" ]


  elasticsearch_exporter:
    image: justwatch/elasticsearch_exporter:latest
    container_name: elasticsearch_exporter
    environment:
      - ELASTICSEARCH_URI=http://elasticsearch:9200
    ports:
      - "9114:9114"


volumes:
  elasticsearch-data:
  prometheus_data: